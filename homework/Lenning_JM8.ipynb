{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8\n",
    "\n",
    "## 1\n",
    "\n",
    "1. I/PRP need/VBP a/DT flight/NN from/IN Atlanta/NN\n",
    "    Atlanta should be a NNP because it is a proper noun\n",
    "2. Does/VBZ this/DT flight/NN serve/VB dinner/NNS\n",
    "    Diiner should be a NN because it is singular\n",
    "3. I/PRP have/VB a/DT friend/NN living/VBG in/IN Denver/NNP \n",
    "    Have should be a VBP because has is the base\n",
    "4. Can/VBP you/PRP list/VB the/DT nonstop/JJ afternoon/NN flights/NNS\n",
    "    Afternoon should be a JJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\n",
    "Use the Penn Treebank tagset to tag each word in the following sentences from Damon Runyon’s short stories. You may ignore punctuation. Some of these are quite difficult; do your best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/alenning/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('It', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('nice', 'JJ'), ('night', 'NN')]\n",
      "[('This', 'DT'), ('crap', 'NN'), ('game', 'NN'), ('is', 'VBZ'), ('over', 'RP'), ('a', 'DT'), ('garage', 'NN'), ('in', 'IN'), ('Fifty-second', 'NNP'), ('Street', 'NNP')]\n",
      "[('Nobody', 'NN'), ('ever', 'RB'), ('takes', 'VBZ'), ('the', 'DT'), ('newspapers', 'NNS'), ('she', 'PRP'), ('sells', 'VBZ')]\n",
      "[('He', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('tall', 'JJ'), ('skinny', 'NN'), ('guy', 'NN'), ('with', 'IN'), ('a', 'DT'), ('long', 'JJ'), ('sad', 'JJ'), ('mean-looking', 'NN'), ('kisser', 'NN'), ('and', 'CC'), ('a', 'DT'), ('mournful', 'JJ'), ('voice', 'NN')]\n",
      "[('I', 'PRP'), ('am', 'VBP'), ('sitting', 'VBG'), ('in', 'IN'), ('Mindys', 'NNP'), ('restaurant', 'NN'), ('putting', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('gefillte', 'NN'), ('fish', 'NN'), ('which', 'WDT'), ('is', 'VBZ'), ('a', 'DT'), ('dish', 'JJ'), ('I', 'PRP'), ('am', 'VBP'), ('very', 'RB'), ('fond', 'NN'), ('of', 'IN')]\n",
      "[('When', 'WRB'), ('a', 'DT'), ('guy', 'NN'), ('and', 'CC'), ('a', 'DT'), ('doll', 'NN'), ('get', 'NN'), ('to', 'TO'), ('taking', 'VBG'), ('peeks', 'NNS'), ('back', 'RB'), ('and', 'CC'), ('forth', 'NN'), ('at', 'IN'), ('each', 'DT'), ('other', 'JJ'), ('why', 'WRB'), ('there', 'EX'), ('you', 'PRP'), ('are', 'VBP'), ('indeed', 'RB')]\n"
     ]
    }
   ],
   "source": [
    "text1 = word_tokenize(\"It is a nice night\")\n",
    "text2 = word_tokenize(\"This crap game is over a garage in Fifty-second Street\")\n",
    "text3 = word_tokenize(\"Nobody ever takes the newspapers she sells\")\n",
    "text4 = word_tokenize(\"He is a tall skinny guy with a long sad mean-looking kisser and a mournful voice\")\n",
    "text5 = word_tokenize(\"I am sitting in Mindys restaurant putting on the gefillte fish which is a dish I am very fond of\")\n",
    "text6 = word_tokenize(\"When a guy and a doll get to taking peeks back and forth at each other why there you are indeed\")\n",
    "\n",
    "print(nltk.pos_tag(text1))\n",
    "print(nltk.pos_tag(text2))\n",
    "print(nltk.pos_tag(text3))\n",
    "print(nltk.pos_tag(text4))\n",
    "print(nltk.pos_tag(text5))\n",
    "print(nltk.pos_tag(text6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\n",
    "Now compare your tags from the previous exercise with one or two friend’s answers. On which words did you disagree the most? Why?\n",
    "\n",
    "Lowry and Ammon both categorized these by hand. It was interesting to compare them to NLTK's answers. It seemed that NLTK mixed up NN and JJ much more frequently than both Lowry and Ammon. For example 'fond' in sentence 5 was categorized by NLTK as a NN but Lowry and Ammon both used JJ.\n",
    "\n",
    "## 4\n",
    "Implement the “most likely tag” baseline. Find a POS-tagged training set, and use it to compute for each word the tag that maximizes p(t|w). You will need to implement a simple tokenizer to deal with sentence boundaries. Start by assuming that all unknown words are NN and compute your error rate on known and unknown words. Now write at least five rules to do a better job of tagging unknown words, and show the difference in error rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "brown_news_tagged = brown.tagged_words(categories='news')\n",
    "brown_train, brown_test = train_test_split(brown_news_tagged, train_size=0.7)\n",
    "\n",
    "def baseline(document):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        document ([type]): [description]\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "    most_common = set()\n",
    "    \n",
    "    tag_fd = nltk.ConditionalFreqDist((word.lower(), tag) for (word, tag) in document)\n",
    "\n",
    "    for word in tag_fd.conditions():\n",
    "        tag = tag_fd[word].max()\n",
    "        most_common.add((word, tag))\n",
    "\n",
    "    return list(most_common)\n",
    "\n",
    "base = baseline(brown_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neither of these implements the 5 rules\n",
      "correctly assigned tags known words: 0.9084080239009816\n",
      "correctly assigned tags unknown words: 0.7254615971094243\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_acc(train, test, unknown=True):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        train ([type]): [description]\n",
    "        test ([type]): [description]\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "\n",
    "    train = pd.DataFrame(train, columns=['word', 'tag_pred'])\n",
    "    test = pd.DataFrame(test, columns=['word', 'tag_act'])\n",
    "\n",
    "    if(unknown):\n",
    "        merged = test.merge(train, how=\"left\", on=\"word\")\n",
    "        merged['tag_pred'] = merged['tag_pred'].replace(np.nan, \"NN\")\n",
    "    else:\n",
    "        merged = test.merge(train, on=\"word\")\n",
    "\n",
    "    merged['score'] = (merged['tag_act'] == merged['tag_pred'])\n",
    "\n",
    "    return 1 - len(merged[merged['score'] == False]) / len(merged)\n",
    "\n",
    "print(\"Neither of these implements the 5 rules\")\n",
    "print(\"correctly assigned tags known words:\", get_acc(base, brown_test, unknown=False))\n",
    "print(\"correctly assigned tags unknown words:\", get_acc(base, brown_test, unknown=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5\n",
    "Build a bigram HMM tagger. You will need a part-of-speech-tagged corpus. First split the corpus into a training set and test set. From the labeled training set, train the transition and observation probabilities of the HMM tagger directly on the hand-tagged data. Then implement the Viterbi algorithm so you can decode a test sentence. Now run your algorithm on the test set. Report its error rate and compare its performance to the most frequent tag baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6\n",
    "Do an error analysis of your tagger. Build a confusion matrix and investigate the most frequent errors. Propose some features for improving the performance of your tagger on these errors."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2038d1479388d82a9505d662a1f330a1e267339975f16223286a8da7ba6dceaa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
